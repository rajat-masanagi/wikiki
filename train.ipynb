{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('wikipedia_eng.txt','r',encoding='utf-8') as f:\n",
                "    text=f.read()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Length:  215106987\n"
                    ]
                }
            ],
            "source": [
                "print(\"Length: \",len(text))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
                        "95\n"
                    ]
                }
            ],
            "source": [
                "chars = sorted(list(set(text)))\n",
                "vocab_size = len(chars)\n",
                "print(''.join(chars))\n",
                "print(vocab_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[72, 73, 73, 1, 84, 72, 69, 82, 69]\n",
                        "hii there\n"
                    ]
                }
            ],
            "source": [
                "stoi = { ch:i for i,ch in enumerate(chars) }\n",
                "itos = { i:ch for i,ch in enumerate(chars) }\n",
                "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
                "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
                "\n",
                "print(encode(\"hii there\"))\n",
                "print(decode(encode(\"hii there\")))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import tiktoken"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# tokenizer=tiktoken.get_encoding(\"cl100k_base\")\n",
                "# vocab_size=100000\n",
                "# tokens=tokenizer.encode(\"hello im rajat\")\n",
                "# print(tokens)\n",
                "# decode=tokenizer.decode(tokens)\n",
                "# print(decode)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([215106987]) <built-in method type of Tensor object at 0x000001D7AB965370>\n",
                        "tensor([34, 80, 82, 73, 76,  1, 73, 83,  1, 84])\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "data=torch.tensor(encode(text),dtype=torch.long)\n",
                "print(data.shape,data.type)\n",
                "print(data[:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Split into Train/Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "n=int(0.9*len(data))\n",
                "train_data=data[:n]\n",
                "test_data=data[n:]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.manual_seed(1234)\n",
                "batch_size=32\n",
                "block_size=8\n",
                "max_iter=3000\n",
                "eval_interval=300\n",
                "learning_rate=1e-2\n",
                "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
                "test_iter=200"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Split into batches"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def batchxy(split):\n",
                "    if split=='train':\n",
                "        data=train_data\n",
                "    else:\n",
                "        data=test_data\n",
                "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
                "    xl=[]\n",
                "    yl=[]\n",
                "    for i in ix:\n",
                "        xl.append(data[i:i+block_size])\n",
                "        yl.append(data[i+1:i+1+block_size])\n",
                "    x=torch.stack(xl)\n",
                "    y=torch.stack(yl)\n",
                "    x,y=x.to(device),y.to(device)\n",
                "    return x,y    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([32, 8])\n",
                        "tensor([[73, 78, 71,  1, 53, 72, 69,  1],\n",
                        "        [88,  1, 78,  1, 31,  1, 76,  1],\n",
                        "        [66, 83, 73, 84, 69, 83,  0, 54],\n",
                        "        [69, 86, 79, 76, 85, 84, 73, 79],\n",
                        "        [23, 18, 23, 20, 10,  0,  1, 45],\n",
                        "        [76, 65, 67, 69,  1, 73, 78,  1],\n",
                        "        [76, 68, 15,  1, 42, 78,  1, 19],\n",
                        "        [ 1, 76, 69, 84, 84, 69, 82, 83],\n",
                        "        [77, 90, 65,  1, 65, 78, 68,  1],\n",
                        "        [ 1, 76, 73, 84, 84, 76, 69,  1],\n",
                        "        [84, 69, 82, 13,  1, 65, 67, 84],\n",
                        "        [84, 69, 82,  1, 73, 78, 67, 76],\n",
                        "        [68,  1, 65, 84,  1, 84, 72, 69],\n",
                        "        [92, 20, 21, 92, 92, 19, 17, 92],\n",
                        "        [84, 72, 73, 79, 80, 73, 65, 78],\n",
                        "        [ 1, 66, 65, 83, 75, 69, 84, 66],\n",
                        "        [84, 90, 69, 82, 76, 65, 78, 68],\n",
                        "        [78, 73, 90, 65, 84, 73, 79, 78],\n",
                        "        [82, 79, 82,  8, 83,  1, 36, 85],\n",
                        "        [ 1, 35, 82, 79, 75, 69, 78,  1],\n",
                        "        [78, 68,  1, 80, 72, 73, 76, 65],\n",
                        "        [65, 84, 72, 69, 82, 13,  1, 44],\n",
                        "        [84, 73, 86, 73, 84, 89,  0, 34],\n",
                        "        [66, 65, 82, 83, 13,  1, 65, 78],\n",
                        "        [ 1, 77, 79, 84, 73, 86, 65, 84],\n",
                        "        [84, 77, 69, 78, 84,  0,  0, 48],\n",
                        "        [71, 73, 78, 69,  1, 36, 69, 83],\n",
                        "        [73, 75, 65, 78, 68, 65, 82,  1],\n",
                        "        [65,  1, 83, 85, 77, 77, 65, 82],\n",
                        "        [72, 65, 86, 69,  1, 87, 73, 84],\n",
                        "        [52,  1, 87, 65, 83,  1, 82, 69],\n",
                        "        [84, 65, 76,  1, 79, 70,  1, 56]])\n",
                        "torch.Size([32, 8])\n",
                        "tensor([[78, 71,  1, 53, 72, 69,  1, 35],\n",
                        "        [ 1, 78,  1, 31,  1, 76,  1, 88],\n",
                        "        [83, 73, 84, 69, 83,  0, 54, 78],\n",
                        "        [86, 79, 76, 85, 84, 73, 79, 78],\n",
                        "        [18, 23, 20, 10,  0,  1, 45, 69],\n",
                        "        [65, 67, 69,  1, 73, 78,  1, 84],\n",
                        "        [68, 15,  1, 42, 78,  1, 19, 17],\n",
                        "        [76, 69, 84, 84, 69, 82, 83,  1],\n",
                        "        [90, 65,  1, 65, 78, 68,  1,  1],\n",
                        "        [76, 73, 84, 84, 76, 69,  1, 66],\n",
                        "        [69, 82, 13,  1, 65, 67, 84, 79],\n",
                        "        [69, 82,  1, 73, 78, 67, 76, 85],\n",
                        "        [ 1, 65, 84,  1, 84, 72, 69,  1],\n",
                        "        [20, 21, 92, 92, 19, 17, 92, 92],\n",
                        "        [72, 73, 79, 80, 73, 65, 78,  1],\n",
                        "        [66, 65, 83, 75, 69, 84, 66, 65],\n",
                        "        [90, 69, 82, 76, 65, 78, 68,  0],\n",
                        "        [73, 90, 65, 84, 73, 79, 78, 83],\n",
                        "        [79, 82,  8, 83,  1, 36, 85, 80],\n",
                        "        [35, 82, 79, 75, 69, 78,  1, 35],\n",
                        "        [68,  1, 80, 72, 73, 76, 65, 78],\n",
                        "        [84, 72, 69, 82, 13,  1, 44, 65],\n",
                        "        [73, 86, 73, 84, 89,  0, 34, 83],\n",
                        "        [65, 82, 83, 13,  1, 65, 78,  1],\n",
                        "        [77, 79, 84, 73, 86, 65, 84, 73],\n",
                        "        [77, 69, 78, 84,  0,  0, 48, 84],\n",
                        "        [73, 78, 69,  1, 36, 69, 83, 83],\n",
                        "        [75, 65, 78, 68, 65, 82,  1, 45],\n",
                        "        [ 1, 83, 85, 77, 77, 65, 82, 89],\n",
                        "        [65, 86, 69,  1, 87, 73, 84, 72],\n",
                        "        [ 1, 87, 65, 83,  1, 82, 69, 78],\n",
                        "        [65, 76,  1, 79, 70,  1, 56, 65]])\n"
                    ]
                }
            ],
            "source": [
                "xb,yb=batchxy('train')\n",
                "print(xb.shape)\n",
                "print(xb)\n",
                "print(yb.shape)\n",
                "print(yb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bigram"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<torch._C.Generator at 0x1d78cad2730>"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.nn import functional as F\n",
                "torch.manual_seed(1234)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def estimate_loss():\n",
                "    out={}\n",
                "    model.eval()\n",
                "    for split in ['train','test']:\n",
                "        losses=torch.zeros(test_iter)\n",
                "        for k in range(test_iter):\n",
                "            X,Y=batchxy(split)\n",
                "            logits,loss=model(X,Y)\n",
                "            losses[k]=loss.item()\n",
                "        out[split]=losses.mean()\n",
                "    model.train()\n",
                "    return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BigramLanguageModel(nn.Module):\n",
                "\n",
                "    def __init__(self, vocab_size):\n",
                "        super().__init__()\n",
                "        # each token directly reads off the logits for the next token from a lookup table\n",
                "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
                "\n",
                "    def forward(self, idx, targets=None):\n",
                "\n",
                "        # idx and targets are both (B,T) tensor of integers\n",
                "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
                "        66\n",
                "        if targets is None:\n",
                "            loss = None\n",
                "        else:\n",
                "            B, T, C = logits.shape\n",
                "            logits = logits.view(B*T, C)\n",
                "            targets = targets.view(B*T)\n",
                "            loss = F.cross_entropy(logits, targets)\n",
                "\n",
                "        return logits, loss\n",
                "    def generate(self, idx, max_new_tokens):\n",
                "        # idx is (B, T) array of indices in the current context\n",
                "        for _ in range(max_new_tokens):\n",
                "            # get the predictions\n",
                "            logits, loss = self(idx)\n",
                "            # focus only on the last time step\n",
                "            logits = logits[:, -1, :] # becomes (B, C)\n",
                "            # apply softmax to get probabilities\n",
                "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
                "            # sample from the distribution\n",
                "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
                "            # append sampled index to the running sequence\n",
                "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
                "        return idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([256, 95])\n",
                        "tensor(5.0978, grad_fn=<NllLossBackward0>)\n",
                        "\n",
                        "$mzG>9n*=Is2DfNZ{F&.bK!|s'vbhOWjv\"_P#6;>h3>h$L&cD)B=4A@Pt9R@+()f3PWiHAK{lb@-NpCIXT2N3P+,g[0-k,y*bK]~\n"
                    ]
                }
            ],
            "source": [
                "model=BigramLanguageModel(vocab_size)\n",
                "m=model.to(device)\n",
                "logits,loss=m(xb,yb)\n",
                "print(logits.shape)\n",
                "print(loss)\n",
                "idx = torch.zeros((1, 1), dtype=torch.long,device=device)\n",
                "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Optimizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer=torch.optim.AdamW(m.parameters(),learning_rate)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "step 0: train loss 5.1475,val loss 5.1395\n",
                        "step 300: train loss 3.0677,val loss 3.0805\n",
                        "step 600: train loss 2.7295,val loss 2.7477\n",
                        "step 900: train loss 2.6664,val loss 2.6881\n",
                        "step 1200: train loss 2.6435,val loss 2.6573\n",
                        "step 1500: train loss 2.6223,val loss 2.6470\n",
                        "step 1800: train loss 2.6266,val loss 2.6393\n",
                        "step 2100: train loss 2.6069,val loss 2.6349\n",
                        "step 2400: train loss 2.6167,val loss 2.6324\n",
                        "step 2700: train loss 2.6173,val loss 2.6331\n",
                        "2.6320106983184814\n",
                        "\n",
                        "Same tynkin f wilome an Ir Inm tansy Catecouthe cithing tom Tha Pige 15)\n",
                        "\n",
                        "Tolsere trbellde Pasppeans\n"
                    ]
                }
            ],
            "source": [
                "for steps in range(max_iter):\n",
                "    if steps%eval_interval==0:\n",
                "        losses=estimate_loss()\n",
                "        print(f\"step {steps}: train loss {losses['train']:.4f},val loss {losses['test']:.4f}\")\n",
                "    xb,yb=batchxy('train')\n",
                "    logits,loss=m(xb,yb)\n",
                "    optimizer.zero_grad(set_to_none=True)\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "print(loss.item())\n",
                "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "chatbot",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
